{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['hamming', 'fft']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import csv\n",
    "import sqlite3 as lite\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# numerical processing and scientific libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# signal processing\n",
    "from scipy.io                     import wavfile\n",
    "from scipy                        import stats, signal\n",
    "from scipy.fftpack                import fft\n",
    "\n",
    "from scipy.signal                 import lfilter, hamming\n",
    "from scipy.fftpack.realtransforms import dct\n",
    "from scikits.talkbox              import segment_axis\n",
    "from scikits.talkbox.features     import mfcc\n",
    "\n",
    "# general purpose\n",
    "import collections\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib                    import stride_tricks\n",
    "\n",
    "from IPython.display              import HTML\n",
    "from base64                       import b64encode\n",
    "\n",
    "# Classification and evaluation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sql\n",
    "\n",
    "import weka.core.jvm as jvm\n",
    "from weka.core.converters import Loader, Saver\n",
    "import weka.core.converters as converters\n",
    "\n",
    "#Pooja's directories:\n",
    "#PATH_WAV=\"F:/set1_wav/\"\n",
    "#PATH_DATASET=\"F:/set1/\"\n",
    "#wekaFilePackage= 'C:\\Users\\Pooja Bhojwani\\wekafiles\\packages'\n",
    "\n",
    "\n",
    "#Arturo's Directories:\n",
    "PATH_WAV=\"C:/Users/Cristina/Documents/MIR/Project/DataSet/set1/set1_wav/\"\n",
    "PATH_DATASET=\"C:/Users/Cristina/Documents/MIR/Project/DataSet/set1/set1/\"\n",
    "wekaFilePackage ='C:\\Users\\Cristina\\wekafiles\\packages'\n",
    "\n",
    "DATASET=\"mean_ratings_set1.csv\"\n",
    "DB=\"CSC_479_MusicInformationRetrieval.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dbInit():\n",
    "    connection = lite.connect(DB)\n",
    "    \n",
    "    with connection:\n",
    "        cursor = connection.cursor() \n",
    "        cursor.execute(\"DROP TABLE IF EXISTS musicFeatures\")\n",
    "        #Add features\n",
    "        cursor.execute(\"CREATE TABLE musicFeatures( \\\n",
    "          id                 TEXT,\\\n",
    "          song               TEXT,\\\n",
    "          path               TEXT,\\\n",
    "          valence            TEXT,\\\n",
    "          energy             TEXT,\\\n",
    "          tension            TEXT,\\\n",
    "          sc_mean            TEXT,\\\n",
    "          sc_std             TEXT,\\\n",
    "          sc_var             TEXT,\\\n",
    "          rms_mean           TEXT,\\\n",
    "          rms_std            TEXT,\\\n",
    "          rms_var            TEXT,\\\n",
    "          sr_mean            TEXT,\\\n",
    "          sr_std             TEXT,\\\n",
    "          sr_var             TEXT,\\\n",
    "          zcr_mean           TEXT,\\\n",
    "          zcr_std            TEXT,\\\n",
    "          zcr_var            TEXT,\\\n",
    "          sf_mean            TEXT,\\\n",
    "          sf_std             TEXT,\\\n",
    "          sf_var             TEXT,\\\n",
    "          pe_mean            TEXT,\\\n",
    "          pe_std             TEXT,\\\n",
    "          pe_var             TEXT,\\\n",
    "          mfcc_mean          TEXT,\\\n",
    "          mfcc_std           TEXT,\\\n",
    "          mfcc_var           TEXT,\\\n",
    "          class              TEXT \\\n",
    "      )\")\n",
    "        \n",
    "    print(\"Table created\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dbInsert(songInfo):\n",
    "    connection = lite.connect(DB)\n",
    "    with connection:\n",
    "        cursor= connection.cursor()\n",
    "        #Add features\n",
    "        cursor.executemany(\"INSERT INTO musicFeatures VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?,\\\n",
    "                                                             ?, ?, ?, ?, ?, ?, ?, ?)\", songInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertToCSV(path):\n",
    "    connection = lite.connect(DB)\n",
    "    \n",
    "    #table = sql.read_frame('select id, song, path, valence, energy, tension, sc_mean, sc_std, sc_var, rms_mean, rms_std, rms_var,  \\\n",
    "    #                               sr_mean, sr_std, sr_var, zcr_mean, zcr_std, zcr_var, sf_mean, sf_std, sf_var, \\\n",
    "    #                               mfcc_mean, mfcc_std, mfcc_var, class \\\n",
    "    #                        from musicFeatures', connection)\n",
    "    dataset=path+'dataset.csv'\n",
    "    #dataset_new= path+'dataset_new.csv'\n",
    "    #the_frame = sql.read_sql_table('musicFeatures', connection)\n",
    "    #table.to_csv(dataset)\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"select * from musicFeatures;\")\n",
    "\n",
    "    with open(dataset, \"wb\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([i[0] for i in cursor.description]) # write headers\n",
    "        csv_writer.writerows(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToARFF(path):\n",
    "   \n",
    "    #jvm.start(class_path = wekaFilePackage)\n",
    "    jvm.start()    \n",
    "    loader = Loader(classname=\"weka.core.converters.CSVLoader\")\n",
    "    data = loader.load_file(path + 'dataset.csv')\n",
    "    #print(data)\n",
    "    saver = Saver(classname=\"weka.core.converters.ArffSaver\")\n",
    "    saver.save_file(data, path + 'dataset.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" short time fourier transform of audio signal \"\"\"\n",
    "def stft(sig, frameSize, overlapFac=0.5, window=np.hanning):\n",
    "    win = window(frameSize)\n",
    "    hopSize = int(frameSize - np.floor(overlapFac * frameSize))\n",
    "    \n",
    "    # zeros at beginning (thus center of 1st window should be for sample nr. 0)\n",
    "    samples = np.append(np.zeros(np.floor(frameSize/2.0)), sig)    \n",
    "    # cols for windowing\n",
    "    cols = np.ceil( (len(samples) - frameSize) / float(hopSize)) + 1\n",
    "    # zeros at end (thus samples can be fully covered by frames)\n",
    "    samples = np.append(samples, np.zeros(frameSize))\n",
    "    \n",
    "    frames = stride_tricks.as_strided(samples, shape=(cols, frameSize), strides=(samples.strides[0]*hopSize, samples.strides[0])).copy()\n",
    "    frames *= win\n",
    "    \n",
    "    return np.fft.rfft(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" plot spectrogram\"\"\"\n",
    "def plotstft(samples, samplerate, binsize=2**10, plotpath=None, colormap=\"jet\", ax=None, fig=None):\n",
    "    \n",
    "    s = stft(samples, binsize)\n",
    "    \n",
    "    sshow, freq = logscale_spec(s, factor=1.0, sr=samplerate)\n",
    "    ims = 20.*np.log10(np.abs(sshow)/10e-6) # amplitude to decibel\n",
    "    \n",
    "    timebins, freqbins = np.shape(ims)\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, sharey=True, figsize=(PLOT_WIDTH, 3.5))\n",
    "    \n",
    "    #ax.figure(figsize=(15, 7.5))\n",
    "    cax = ax.imshow(np.transpose(ims), origin=\"lower\", aspect=\"auto\", cmap=colormap, interpolation=\"none\")\n",
    "    #cbar = fig.colorbar(cax, ticks=[-1, 0, 1], cax=ax)\n",
    "    #ax.set_colorbar()\n",
    "\n",
    "    ax.set_xlabel(\"time (s)\")\n",
    "    ax.set_ylabel(\"frequency (hz)\")\n",
    "    ax.set_xlim([0, timebins-1])\n",
    "    ax.set_ylim([0, freqbins])\n",
    "\n",
    "    xlocs = np.float32(np.linspace(0, timebins-1, 5))\n",
    "    ax.set_xticks(xlocs, [\"%.02f\" % l for l in ((xlocs*len(samples)/timebins)+(0.5*binsize))/samplerate])\n",
    "    ylocs = np.int16(np.round(np.linspace(0, freqbins-1, 10)))\n",
    "    ax.set_yticks(ylocs, [\"%.02f\" % freq[i] for i in ylocs])\n",
    "    \n",
    "    if plotpath:\n",
    "        plt.savefig(plotpath, bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "    #plt.clf();\n",
    "    b = [\"%.02f\" % l for l in ((xlocs*len(samples)/timebins)+(0.5*binsize))/samplerate]\n",
    "    return xlocs, b, timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" scale frequency axis logarithmically \"\"\"    \n",
    "def logscale_spec(spec, sr=44100, factor=20.):\n",
    "    timebins, freqbins = np.shape(spec)\n",
    "\n",
    "    scale = np.linspace(0, 1, freqbins) ** factor\n",
    "    scale *= (freqbins-1)/max(scale)\n",
    "    scale = np.unique(np.round(scale))\n",
    "    \n",
    "    # create spectrogram with new freq bins\n",
    "    newspec = np.complex128(np.zeros([timebins, len(scale)]))\n",
    "    for i in range(0, len(scale)):\n",
    "        if i == len(scale)-1:\n",
    "            newspec[:,i] = np.sum(spec[:,scale[i]:], axis=1)\n",
    "        else:        \n",
    "            newspec[:,i] = np.sum(spec[:,scale[i]:scale[i+1]], axis=1)\n",
    "    \n",
    "    # list center freq of bins\n",
    "    allfreqs = np.abs(np.fft.fftfreq(freqbins*2, 1./sr)[:freqbins+1])\n",
    "    freqs = []\n",
    "    for i in range(0, len(scale)):\n",
    "        if i == len(scale)-1:\n",
    "            freqs += [np.mean(allfreqs[scale[i]:])]\n",
    "        else:\n",
    "            freqs += [np.mean(allfreqs[scale[i]:scale[i+1]])]\n",
    "    \n",
    "    return newspec, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spectralCentroid(wavedata, window_size, sample_rate):\n",
    "    magnitude_spectrum = stft(wavedata, window_size)\n",
    "    timebins, freqbins = np.shape(magnitude_spectrum)\n",
    "    # when do these blocks begin (time in seconds)?\n",
    "    timestamps = (np.arange(0,timebins - 1) * (timebins / float(sample_rate)))\n",
    "    sc = []\n",
    "\n",
    "    for t in range(timebins-1):\n",
    "        power_spectrum = np.abs(magnitude_spectrum[t])**2\n",
    "        sc_t = np.sum(power_spectrum * np.arange(1,freqbins+1)) / np.sum(power_spectrum)\n",
    "        sc.append(sc_t)\n",
    "        \n",
    "    sc = np.asarray(sc)\n",
    "    sc = np.nan_to_num(sc)\n",
    "    \n",
    "    return sc, np.asarray(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotFeatureSpectogram(feature_data, timestamps, squared_wf=False):\n",
    "    # plot spectrogram\n",
    "    a,b,c = plotstft(sound_files[\"wavedata\"], sound_files[\"samplerate\"]);\n",
    "\n",
    "    fig = plt.figure(num=None, figsize=(PLOT_WIDTH, PLOT_HEIGHT), dpi=72, facecolor='w', edgecolor='k');\n",
    "    channel_1 = fig.add_subplot(111);\n",
    "    channel_1.set_ylabel('Channel 1');\n",
    "    channel_1.set_xlabel('time');\n",
    "\n",
    "    # plot waveform\n",
    "    scaled_wf_y = ((np.arange(0,sound_files[\"wavedata\"].shape[0]).astype(np.float)) / sound_files[\"samplerate\"]) * 1000.0\n",
    "    \n",
    "    if squared_wf:\n",
    "        scaled_wf_x = (sound_files[\"wavedata\"]**2 / np.max(sound_files[\"wavedata\"]**2))\n",
    "    else:\n",
    "        scaled_wf_x = (sound_files[\"wavedata\"] / np.max(sound_files[\"wavedata\"]) / 2.0 ) + 0.5\n",
    "    \n",
    "    #scaled_wf_x = scaled_wf_x**2\n",
    "    \n",
    "    plt.plot(scaled_wf_y, scaled_wf_x, color='lightgrey');\n",
    "\n",
    "    # plot feature-data\n",
    "    scaled_fd_y = timestamps * 1000.0\n",
    "    scaled_fd_x = (feature_data / np.max(feature_data))\n",
    "    \n",
    "    plt.plot(scaled_fd_y, scaled_fd_x, color='r');\n",
    "\n",
    "    plt.show();\n",
    "    plt.clf();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rms(wavedata, block_length, sample_rate):\n",
    "    # how many blocks have to be processed?\n",
    "    num_blocks = int(np.ceil(len(wavedata)/block_length))\n",
    "    # when do these blocks begin (time in seconds)?\n",
    "    # timestamps = (np.arange(0,num_blocks - 1) * (block_length / float(samplerate)))\n",
    "    rms = []\n",
    "    for i in range(0,num_blocks-1):\n",
    "        start = i * block_length\n",
    "        stop  = np.min([(start + block_length - 1), len(wavedata)])\n",
    "        rms_seg = float(np.sqrt(np.mean(wavedata[start:stop]**2)))\n",
    "        x=float('nan')\n",
    "        if not math.isnan(rms_seg):\n",
    "            rms.append(rms_seg)\n",
    "        #print(rms)\n",
    "    return np.asarray(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spectralRolloff(wavedata, window_size, sample_rate, k=0.85):    \n",
    "    # convert to frequency domain\n",
    "    magnitude_spectrum = stft(wavedata, window_size)\n",
    "    power_spectrum     = np.abs(magnitude_spectrum)**2\n",
    "    timebins, freqbins = np.shape(magnitude_spectrum)\n",
    "    # when do these blocks begin (time in seconds)?\n",
    "    #timestamps = (np.arange(0,timebins - 1) * (timebins / float(sample_rate)))\n",
    "    \n",
    "    sr = []\n",
    "\n",
    "    spectralSum    = np.sum(power_spectrum, axis=1)\n",
    "    \n",
    "    for t in range(timebins-1):\n",
    "        # find frequency-bin indeces where the cummulative sum of all bins is higher\n",
    "        # than k-percent of the sum of all bins. Lowest index = Rolloff\n",
    "        sr_t = np.where(np.cumsum(power_spectrum[t,:]) >= k * spectralSum[t])[0][0]\n",
    "        sr.append(sr_t)\n",
    "    sr = np.asarray(sr).astype(float)\n",
    "    \n",
    "    # convert frequency-bin index to frequency in Hz\n",
    "    sr = (sr / freqbins) * (sample_rate / 2.0)\n",
    "    \n",
    "    return sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_crossing_rate(wavedata, block_length, sample_rate):    \n",
    "    # how many blocks have to be processed?\n",
    "    num_blocks = int(np.ceil(len(wavedata)/block_length))\n",
    "    # when do these blocks begin (time in seconds)?\n",
    "    timestamps = (np.arange(0,num_blocks - 1) * (block_length / float(samplerate)))\n",
    "    \n",
    "    zcr = []\n",
    "    \n",
    "    for i in range(0,num_blocks-1):        \n",
    "        start = i * block_length\n",
    "        stop  = np.min([(start + block_length - 1), len(wavedata)])        \n",
    "        zc = 0.5 * np.mean(np.abs(np.diff(np.sign(wavedata[start:stop]))))\n",
    "        zcr.append(zc)\n",
    "        \n",
    "    return np.asarray(zcr), np.asarray(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spectral_flux(wavedata, window_size, sample_rate):    \n",
    "    # convert to frequency domain\n",
    "    magnitude_spectrum = stft(wavedata, window_size)\n",
    "    timebins, freqbins = np.shape(magnitude_spectrum)    \n",
    "    # when do these blocks begin (time in seconds)?\n",
    "    timestamps = (np.arange(0,timebins - 1) * (timebins / float(sample_rate)))\n",
    "    \n",
    "    sf = np.sqrt(np.sum(np.diff(np.abs(magnitude_spectrum))**2, axis=1)) / freqbins\n",
    "    \n",
    "    return sf[1:], np.asarray(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pitch_extract(file):\n",
    "    import subprocess\n",
    "    os.chdir(PATH_WAV)\n",
    "    subprocess.check_output(PATH_WAV + '/pitchextract.exe -w 1024 -l 3 -u 256 ' + PATH_WAV + file, shell=True)\n",
    "    pitchpath = '\\pitch.txt'\n",
    "    os.chdir(PATH_WAV)\n",
    "    cwd = os.getcwd()\n",
    "    #print cwd, pitchpath\n",
    "    pitchfile = cwd + pitchpath\n",
    "    f = open(pitchfile, 'r')\n",
    "    #print \"File\" + file\n",
    "    lines = [line.rstrip('\\n') for line in f]\n",
    "    results = [float(i) for i in lines]\n",
    "    #temp = list()\n",
    "    #for line in lines:\n",
    "    #    if isinstance(line, str):\n",
    "    #        line = float(line)\n",
    "            #print line,type(line)\n",
    "    return results\n",
    "    #return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mfcc_extract(wavedata):\n",
    "        # Parameters\n",
    "        nwin    = 256\n",
    "        nfft    = 1024\n",
    "        fs      = 16000\n",
    "        nceps   = 13\n",
    "\n",
    "        # Pre-emphasis factor (to take into account the -6dB/octave\n",
    "        # rolloff of the radiation at the lips level)\n",
    "        prefac  = 0.97\n",
    "\n",
    "        # MFCC parameters: taken from auditory toolbox\n",
    "        over    = nwin - 160\n",
    "\n",
    "        filtered_data = lfilter([1., -prefac], 1, wavedata)\n",
    "        \n",
    "        windows     = hamming(256, sym=0)\n",
    "        framed_data = segment_axis(filtered_data, nwin, over) * windows\n",
    "\n",
    "        # Compute the spectrum magnitude\n",
    "        magnitude_spectrum = np.abs(fft(framed_data, nfft, axis=-1))\n",
    "        \n",
    "        \n",
    "        # Compute triangular filterbank for MFCC computation.\n",
    "\n",
    "        lowfreq  = 133.33\n",
    "        linsc    = 200/3.\n",
    "        logsc    = 1.0711703\n",
    "        fs = 44100\n",
    "\n",
    "        nlinfilt = 13\n",
    "        nlogfilt = 27\n",
    "\n",
    "        # Total number of filters\n",
    "        nfilt    = nlinfilt + nlogfilt\n",
    "\n",
    "        #------------------------\n",
    "        # Compute the filter bank\n",
    "        #------------------------\n",
    "        # Compute start/middle/end points of the triangular filters in spectral\n",
    "        # domain\n",
    "        freqs            = np.zeros(nfilt+2)\n",
    "        freqs[:nlinfilt] = lowfreq + np.arange(nlinfilt) * linsc\n",
    "        freqs[nlinfilt:] = freqs[nlinfilt-1] * logsc ** np.arange(1, nlogfilt + 3)\n",
    "        heights          = 2./(freqs[2:] - freqs[0:-2])\n",
    "\n",
    "        # Compute filterbank coeff (in fft domain, in bins)\n",
    "        filterbank  = np.zeros((nfilt, nfft))\n",
    "\n",
    "        # FFT bins (in Hz)\n",
    "        nfreqs = np.arange(nfft) / (1. * nfft) * fs\n",
    "\n",
    "        for i in range(nfilt):\n",
    "    \n",
    "            low = freqs[i]\n",
    "            cen = freqs[i+1]\n",
    "            hi  = freqs[i+2]\n",
    "            lid    = np.arange(np.floor(low * nfft / fs) + 1,\n",
    "                       np.floor(cen * nfft / fs) + 1, dtype=np.int)\n",
    "            rid    = np.arange(np.floor(cen * nfft / fs) + 1,\n",
    "                       np.floor(hi * nfft / fs)  + 1, dtype=np.int)\n",
    "            lslope = heights[i] / (cen - low)\n",
    "            rslope = heights[i] / (hi - cen)\n",
    "            filterbank[i][lid] = lslope * (nfreqs[lid] - low)\n",
    "            filterbank[i][rid] = rslope * (hi - nfreqs[rid])\n",
    "        \n",
    "        # apply filter\n",
    "        mspec = np.log10(np.dot(magnitude_spectrum, filterbank.T))\n",
    "        \n",
    "        # Compute triangular filterbank for MFCC computation.\n",
    "\n",
    "        lowfreq  = 133.33\n",
    "        linsc    = 200/3.\n",
    "        logsc    = 1.0711703\n",
    "        fs = 44100\n",
    "\n",
    "        nlinfilt = 13\n",
    "        nlogfilt = 27\n",
    "\n",
    "        # Total number of filters\n",
    "        nfilt    = nlinfilt + nlogfilt\n",
    "\n",
    "        #------------------------\n",
    "        # Compute the filter bank\n",
    "        #------------------------\n",
    "        # Compute start/middle/end points of the triangular filters in spectral\n",
    "        # domain\n",
    "        freqs            = np.zeros(nfilt+2)\n",
    "        freqs[:nlinfilt] = lowfreq + np.arange(nlinfilt) * linsc\n",
    "        freqs[nlinfilt:] = freqs[nlinfilt-1] * logsc ** np.arange(1, nlogfilt + 3)\n",
    "        heights          = 2./(freqs[2:] - freqs[0:-2])\n",
    "\n",
    "        # Compute filterbank coeff (in fft domain, in bins)\n",
    "        filterbank  = np.zeros((nfilt, nfft))\n",
    "\n",
    "        # FFT bins (in Hz)\n",
    "        nfreqs = np.arange(nfft) / (1. * nfft) * fs\n",
    "        \n",
    "        for i in range(nfilt):\n",
    "                \n",
    "                low = freqs[i]\n",
    "                cen = freqs[i+1]\n",
    "                hi  = freqs[i+2]\n",
    "                \n",
    "                lid    = np.arange(np.floor(low * nfft / fs) + 1,\n",
    "                           np.floor(cen * nfft / fs) + 1, dtype=np.int)\n",
    "                \n",
    "                rid    = np.arange(np.floor(cen * nfft / fs) + 1,\n",
    "                           np.floor(hi * nfft / fs)  + 1, dtype=np.int)\n",
    "                \n",
    "                lslope = heights[i] / (cen - low)\n",
    "                rslope = heights[i] / (hi - cen)\n",
    "                \n",
    "                filterbank[i][lid] = lslope * (nfreqs[lid] - low)\n",
    "                filterbank[i][rid] = rslope * (hi - nfreqs[rid])\n",
    "        \n",
    "        # apply filter\n",
    "        mspec = np.log10(np.dot(magnitude_spectrum, filterbank.T))\n",
    "        \n",
    "        #fig, ax = plt.subplots(2, 1, sharey=True, figsize=(PLOT_WIDTH, 5.5))\n",
    "        #cax = ax[0].imshow(np.transpose(magnitude_spectrum), origin=\"lower\", aspect=\"auto\",  interpolation=\"nearest\")\n",
    "        #cax = ax[1].imshow(np.transpose(mspec), origin=\"lower\", aspect=\"auto\",  interpolation=\"nearest\")\n",
    "        plt.show()\n",
    "        ## Use the DCT to 'compress' the coefficients (spectrum -> cepstrum domain)\n",
    "        MFCCs = dct(mspec, type=2, norm='ortho', axis=-1)[:, :nceps]\n",
    "        MFCCs, mspec, spec = mfcc(wavedata)\n",
    "        return MFCCs\n",
    "        \n",
    "        #fig, ax = plt.subplots(1, 1, sharey=True, figsize=(PLOT_WIDTH, 3.5))\n",
    "        #cax = ax.imshow(np.transpose(MFCCs), origin=\"lower\", aspect=\"auto\",  interpolation=\"nearest\")\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metrics(data, feature, aggregators):   \n",
    "    for aggr_name in aggregators:        \n",
    "        if aggr_name == \"mean\":\n",
    "            mean=np.mean(data[feature])\n",
    "            #print(\"mean: %f \" % mean)\n",
    "        elif aggr_name == \"std\":\n",
    "            std=np.std(data[feature])\n",
    "            #print(\"Standard Deviation: %f\" % std)\n",
    "        elif aggr_name == \"var\":\n",
    "            var=np.var(data[feature])\n",
    "            #print(\"Variance: %f\" % var)\n",
    "    return mean,std, var    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printMetrics(mean, std, var):\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"           Metrics                  \")\n",
    "    print(\"------------------------------------\")\n",
    "    print(\" Mean     |   Standard D  |  Variance  \")\n",
    "    print(\"%f     %f      %f     \"%(mean,std,var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readCSV(file_name,id,sound_files):\n",
    "    #['1', '4.83', '6.83', '3.17', '1.00', '1.00', '7.33', '1.00', '1.00', 'HAPPY', '', '']\n",
    "    with open (file_name) as f:\n",
    "        #print(file_name)\n",
    "        readCSV = csv.reader (f, delimiter=',')\n",
    "        readCSV.next()\n",
    "        for row in readCSV:\n",
    "            songId= int(row[0])\n",
    "            if (songId==id):\n",
    "                valence=row[1]\n",
    "                energy=row[2]\n",
    "                tension=row[3]\n",
    "                classe=row[9]\n",
    "                return valence, energy, tension, classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created\n",
      "Song: C:/Users/Cristina/Documents/MIR/Project/DataSet/set1/set1_wav/001.wav\n",
      "Song: C:/Users/Cristina/Documents/MIR/Project/DataSet/set1/set1_wav/002.wav"
     ]
    }
   ],
   "source": [
    "#defaultdict means that if a key is not found in the dictionary, then instead of a KeyError being thrown, \n",
    "#a new entry is created.\n",
    "# initialize music collection\n",
    "dbInit()\n",
    "sound_files = collections.defaultdict(dict)\n",
    "\n",
    "for filename in sorted(os.listdir(PATH_WAV)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        song=PATH_WAV+filename\n",
    "        samplerate, wavedata = wavfile.read(song)\n",
    "        id=filename[0:-4]\n",
    "        \n",
    "        sound_files[\"path\"]= song\n",
    "        sound_files[\"id\"]=id\n",
    "        sound_files[\"samplerate\"]        = samplerate\n",
    "        sound_files[\"wavedata\"]          = wavedata\n",
    "        sound_files[\"number_of_samples\"] = wavedata.shape[0]\n",
    "        sound_files[\"song_length\"]       = int( sound_files[\"number_of_samples\"] / samplerate ) # round up\n",
    "                \n",
    "        sound_files[\"sc\"]= spectralCentroid(sound_files[\"wavedata\"], 1024, sound_files[\"samplerate\"])\n",
    "        print(\"Song: %s\" % song)\n",
    "        #print(sound_files)\n",
    "        sound_files[\"sc_mean\"],sound_files[\"sc_std\"],sound_files[\"sc_var\"]= metrics(sound_files, \"sc\", [\"mean\", \"std\",\"var\"])\n",
    "        #printMetrics(mean,std,var)\n",
    "        \n",
    "        sound_files[\"rms\"]= rms(sound_files[\"wavedata\"], 2048, sound_files[\"samplerate\"]);\n",
    "        #print(sound_files[\"rms\"])\n",
    "        sound_files[\"rms_mean\"],sound_files[\"rms_std\"],sound_files[\"rms_var\"]= metrics(sound_files, \"rms\", [\"mean\", \"std\",\"var\"])\n",
    "        #printMetrics(mean,std,var)\n",
    "        \n",
    "        sound_files[\"sr\"]= spectralRolloff(sound_files[\"wavedata\"],1024, sound_files[\"samplerate\"],k=0.85)\n",
    "        sound_files[\"sr_mean\"],sound_files[\"sr_std\"],sound_files[\"sr_var\"]= metrics(sound_files, \"sr\", [\"mean\", \"std\",\"var\"])\n",
    "        #printMetrics(mean,std,var)\n",
    "        \n",
    "        sound_files[\"zcr\"]= zero_crossing_rate(sound_files[\"wavedata\"], 2048, sound_files[\"samplerate\"]);\n",
    "        sound_files[\"zcr_mean\"],sound_files[\"zcr_std\"],sound_files[\"zcr_var\"]= metrics(sound_files, \"zcr\", [\"mean\", \"std\",\"var\"])\n",
    "        #printMetrics(mean,std,var)\n",
    "        \n",
    "        sound_files[\"sf\"]= spectral_flux(sound_files[\"wavedata\"], 1024, sound_files[\"samplerate\"]);\n",
    "        sound_files[\"sf_mean\"],sound_files[\"sf_std\"],sound_files[\"sf_var\"]= metrics(sound_files, \"sf\", [\"mean\", \"std\",\"var\"])\n",
    "        #printMetrics(mean,std,var)\n",
    "        \n",
    "        sound_files[\"pe\"] = pitch_extract(filename)\n",
    "        #pitch_extract(filename)\n",
    "        #print metrics(sound_files, \"pe\", [\"mean\", \"std\",\"var\"])\n",
    "        sound_files[\"pe_mean\"],sound_files[\"pe_std\"],sound_files[\"pe_var\"]= metrics(sound_files, \"pe\", [\"mean\", \"std\",\"var\"])\n",
    "        #mean,std,var= metrics(sound_files, \"pe\", [\"mean\", \"std\",\"var\"])\n",
    "        #printMetrics(mean,std,var)\n",
    "        \n",
    "        sound_files[\"mfcc\"]= mfcc_extract(sound_files[\"wavedata\"])\n",
    "        sound_files[\"mfcc_mean\"],sound_files[\"mfcc_std\"],sound_files[\"mfcc_var\"]= metrics(sound_files, \"mfcc\", [\"mean\", \"std\",\"var\"])\n",
    "        #printMetrics(mean,std,var)\n",
    "        #print sound_files[\"mfcc_mean\"],sound_files[\"mfcc_std\"],sound_files[\"mfcc_var\"]\n",
    "        \n",
    "        dataset=PATH_DATASET+DATASET\n",
    "        ID=float(id)\n",
    "        sound_files[\"valence\"],sound_files[\"energy\"],sound_files[\"tension\"],sound_files[\"class\"]=readCSV(dataset,ID,sound_files)\n",
    "        \n",
    "        songInfo = [(str(sound_files[\"id\"]),str(filename),str(sound_files[\"path\"]),\\\n",
    "                     str(sound_files[\"valence\"]), str(sound_files[\"energy\"]),str(sound_files[\"tension\"]),\\\n",
    "                     str(sound_files[\"sc_mean\"]), str(sound_files[\"sc_std\"]),str(sound_files[\"sc_var\"]),\\\n",
    "                     str(sound_files[\"rms_mean\"]), str(sound_files[\"sc_std\"]),str(sound_files[\"sc_var\"]),\\\n",
    "                     str(sound_files[\"sr_mean\"]), str(sound_files[\"sr_std\"]),str(sound_files[\"sr_var\"]), \\\n",
    "                     str(sound_files[\"zcr_mean\"]), str(sound_files[\"zcr_std\"]),str(sound_files[\"zcr_var\"]),\\\n",
    "                     str(sound_files[\"sf_mean\"]), str(sound_files[\"sf_std\"]),str(sound_files[\"sf_var\"]),\\\n",
    "                     str(sound_files[\"pe_mean\"]), str(sound_files[\"pe_std\"]),str(sound_files[\"pe_var\"]),\\\n",
    "                     str(sound_files[\"mfcc_mean\"]), str(sound_files[\"mfcc_std\"]),str(sound_files[\"mfcc_var\"]),\\\n",
    "                     str(sound_files[\"class\"]))]\n",
    "       \n",
    "        #print(songInfo)\n",
    "        dbInsert(songInfo)\n",
    "        convertToCSV(PATH_DATASET)\n",
    "        convertToARFF(PATH_DATASET)\n",
    "        \n",
    "        \n",
    "        #plotFeatureSpectogram(sc, ts, squared_wf=False);\n",
    "        #songInfo = [(str(id),str(filename),str(path),str(sc),str(zcr),str(sf),)]\n",
    "        #dbInsert(songInfo)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
